{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import ImageDataset, DSubset, Label, get_channel_means_stdevs\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {1: 'Airplane', 2: 'Automobile', 3: 'Bird', 4: 'Cat', 5: 'Deer', 6: 'Dog', 7: 'Frog', 8: 'Horse', 9: 'Ship', 10: 'Truck'}\n",
    "\n",
    "with open('../results/channel_training_statistics.pkl', 'rb') as f:\n",
    "    training_channel_means, training_channel_stdevs = pickle.load(f)\n",
    "    \n",
    "tf = Compose([\n",
    "    Normalize(training_channel_means, training_channel_stdevs)\n",
    "])\n",
    "\n",
    "label_type = Label.REAL_OR_SYNTHETIC\n",
    "\n",
    "train_dataset = ImageDataset(DSubset.TRAIN, label_type, transform = tf)\n",
    "test_dataset = ImageDataset(DSubset.TEST, label_type, transform = tf)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 3\n",
    "train_channel_means, train_channel_stdevs = get_channel_means_stdevs(train_dataloader, num_channels = num_channels, verbose = False)\n",
    "\n",
    "# Verify successful standardization functionality: mean 0 and standard deviation 1 on training set\n",
    "assert np.allclose(np.array(train_channel_means), np.zeros(num_channels), atol = 1e-5)\n",
    "assert np.allclose(np.array(train_channel_stdevs), np.ones(num_channels), atol = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 5, 5), # [BATCH_SIZE, 3, 32, 32] -> [BATCH_SIZE, 5, 28, 28]\n",
    "            nn.BatchNorm2d(5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2), # [BATCH_SIZE, 5, 28, 28] -> [BATCH_SIZE, 5, 14, 14]\n",
    "            nn.Conv2d(5, 15, 5), # [BATCH_SIZE, 5, 14, 14] -> [BATCH_SIZE, 15, 10, 10]\n",
    "            nn.BatchNorm2d(15),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2), # [BATCH_SIZE, 15, 10, 10] -> [BATCH_SIZE, 15, 5, 5]\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(15 * 5 * 5, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, start_dim = 1) # Flatten all dimensions except batch (dim 0)\n",
    "        x = self.linear_layers(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x # probability of class 1 (synthetic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
